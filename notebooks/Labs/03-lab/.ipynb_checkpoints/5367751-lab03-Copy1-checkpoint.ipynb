{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56903aa6-b1a9-48ce-97a2-841d6f66ca3e",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "    Lab 03\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ef324-dfe2-488d-99e9-0628d94caaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages yippiee\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e2afa2-80ab-4ac0-88b1-71762e5cac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusbal function to display confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480d3e4-01ce-4f51-9844-868ea158b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the dataset\n",
    "# Assuming the dataset is in a directory structure with images and a CSV file with labels\n",
    "\n",
    "# Define the path to your data\n",
    "data_dir = 'data/chinese_mnist'  # This should be the path to the directory containing the data\n",
    "metadata_path = os.path.join(data_dir, 'chinese_mnist.csv')  # Path to the CSV file with labels\n",
    "\n",
    "# Load the metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "print(\"Dataset metadata sample:\")\n",
    "print(metadata.head())\n",
    "\n",
    "# Display some basic statistics about the dataset\n",
    "print(f\"Total number of images: {len(metadata)}\")\n",
    "print(f\"Number of unique classes: {metadata['value'].nunique()}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(metadata['value'].value_counts())\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(metadata, data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, row in metadata.iterrows():\n",
    "        # Construct file path from metadata\n",
    "        # Adjust this according to your actual file naming convention\n",
    "        file_name = f\"input_{row['suite_id']}_{row['sample_id']}_{row['value']}.jpg\"\n",
    "        file_path = os.path.join(data_dir, 'images', file_name)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Read and preprocess the image\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(row['value'])\n",
    "        \n",
    "        # Print progress every 1000 images\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f\"Processed {idx + 1} images\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load all images and their labels\n",
    "print(\"Loading images...\")\n",
    "X, y = load_images(metadata, data_dir)\n",
    "print(f\"Loaded {len(X)} images with shape {X[0].shape}\")\n",
    "\n",
    "# Visualize some examples\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Split and sample the dataset\n",
    "# Function to perform stratified sampling\n",
    "def stratified_sample(X, y, n_samples):\n",
    "    unique_classes = np.unique(y)\n",
    "    samples_per_class = n_samples // len(unique_classes)\n",
    "    \n",
    "    sampled_X = []\n",
    "    sampled_y = []\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        # Get indices of samples belonging to this class\n",
    "        indices = np.where(y == cls)[0]\n",
    "        \n",
    "        # Randomly select the required number of samples\n",
    "        selected_indices = np.random.choice(indices, size=samples_per_class, replace=False)\n",
    "        \n",
    "        # Add the selected samples to our lists\n",
    "        sampled_X.extend(X[selected_indices])\n",
    "        sampled_y.extend(y[selected_indices])\n",
    "    \n",
    "    return np.array(sampled_X), np.array(sampled_y)\n",
    "\n",
    "# Function to perform evaluation with different training set sizes\n",
    "def evaluate_classifiers(X, y, train_sizes=[5000, 10000], test_size=1000):\n",
    "    results = []\n",
    "    \n",
    "    for train_size in train_sizes:\n",
    "        print(f\"\\nEvaluating with {train_size} training samples and {test_size} test samples\")\n",
    "        \n",
    "        # Sample the data\n",
    "        X_train_sampled, y_train_sampled = stratified_sample(X, y, train_size)\n",
    "        X_test_sampled, y_test_sampled = stratified_sample(X, y, test_size)\n",
    "        \n",
    "        # Step 4: Perform necessary data reshaping\n",
    "        # Flatten the images from 2D to 1D arrays\n",
    "        X_train_flattened = X_train_sampled.reshape(X_train_sampled.shape[0], -1)\n",
    "        X_test_flattened = X_test_sampled.reshape(X_test_sampled.shape[0], -1)\n",
    "        \n",
    "        # Check the class distribution in training and test sets\n",
    "        print(\"Training set class distribution:\")\n",
    "        unique, counts = np.unique(y_train_sampled, return_counts=True)\n",
    "        print(dict(zip(unique, counts)))\n",
    "        \n",
    "        print(\"Test set class distribution:\")\n",
    "        unique, counts = np.unique(y_test_sampled, return_counts=True)\n",
    "        print(dict(zip(unique, counts)))\n",
    "        \n",
    "        # Initialize the classifiers\n",
    "        classifiers = {\n",
    "            'KNN (k=3)': KNeighborsClassifier(n_neighbors=3),\n",
    "            'Decision Tree': DecisionTreeClassifier(),\n",
    "            'SGD (epochs=250)': SGDClassifier(max_iter=250)\n",
    "        }\n",
    "        \n",
    "        class_names = np.unique(y)\n",
    "        \n",
    "        for name, clf in classifiers.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            \n",
    "            # Step 6: Fit the classifier to the training data\n",
    "            clf.fit(X_train_flattened, y_train_sampled)\n",
    "            \n",
    "            # Step 7: Evaluate the trained model on the testing data\n",
    "            y_pred = clf.predict(X_test_flattened)\n",
    "            \n",
    "            # Step 8: Report the performance metrics\n",
    "            accuracy = accuracy_score(y_test_sampled, y_pred)\n",
    "            precision = precision_score(y_test_sampled, y_pred, average='weighted')\n",
    "            recall = recall_score(y_test_sampled, y_pred, average='weighted')\n",
    "            f1 = f1_score(y_test_sampled, y_pred, average='weighted')\n",
    "            \n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Precision: {precision:.4f}\")\n",
    "            print(f\"Recall: {recall:.4f}\")\n",
    "            print(f\"F1 Score: {f1:.4f}\")\n",
    "            \n",
    "            # Calculate and display confusion matrix\n",
    "            cm = confusion_matrix(y_test_sampled, y_pred)\n",
    "            plot_confusion_matrix(cm, class_names, f\"Confusion Matrix - {name} (Train Size: {train_size})\")\n",
    "            \n",
    "            # Detailed classification report\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test_sampled, y_pred))\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Classifier': name,\n",
    "                'Train Size': train_size,\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1 Score': f1\n",
    "            })\n",
    "    \n",
    "    # Create a DataFrame with all results for easy comparison\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nSummary of all results:\")\n",
    "    print(results_df)\n",
    "    \n",
    "    # Plot comparison of classifier performance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Group by classifier and train size\n",
    "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score']:\n",
    "        plt.subplot(2, 2, ['Accuracy', 'Precision', 'Recall', 'F1 Score'].index(metric) + 1)\n",
    "        \n",
    "        for train_size in train_sizes:\n",
    "            subset = results_df[results_df['Train Size'] == train_size]\n",
    "            plt.bar(\n",
    "                np.arange(len(subset)) + (0.4 if train_size == train_sizes[0] else 0), \n",
    "                subset[metric], \n",
    "                width=0.4, \n",
    "                label=f'Train Size: {train_size}'\n",
    "            )\n",
    "        \n",
    "        plt.title(f'{metric} Comparison')\n",
    "        plt.xticks(np.arange(len(subset)), subset['Classifier'])\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Run the evaluation\n",
    "results = evaluate_classifiers(X, y, train_sizes=[5000, 10000], test_size=1000)\n",
    "\n",
    "# Conclusions and discussion\n",
    "print(\"\\nConclusions:\")\n",
    "print(\"1. Effect of increasing training set size:\")\n",
    "for classifier in results['Classifier'].unique():\n",
    "    size_5k = results[(results['Classifier'] == classifier) & (results['Train Size'] == 5000)]\n",
    "    size_10k = results[(results['Classifier'] == classifier) & (results['Train Size'] == 10000)]\n",
    "    \n",
    "    acc_diff = size_10k['Accuracy'].values[0] - size_5k['Accuracy'].values[0]\n",
    "    print(f\"   - {classifier}: Accuracy change = {acc_diff:.4f}\")\n",
    "\n",
    "print(\"\\n2. Best performing classifier:\")\n",
    "best_acc = results.loc[results['Accuracy'].idxmax()]\n",
    "print(f\"   - {best_acc['Classifier']} with training size {best_acc['Train Size']} achieved the highest accuracy: {best_acc['Accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n3. Other observations:\")\n",
    "print(\"   - [Add your observations here based on the actual results]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f9bdc-c60b-43a5-a7a4-54b395efbd21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
